<html>
<head>
  <meta charset="utf-8" />
<meta name="description" content="" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<title>我的第一个python爬虫 | 一只小菜鸡</title>
<link rel="shortcut icon" href="https://sixi.fun/favicon.ico?v=1560515429400">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
<link rel="stylesheet" href="https://sixi.fun/styles/main.css" type='text/css' media='all'>

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script src="https://cdn.bootcss.com/moment.js/2.23.0/moment.min.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">



</head>
<body class="home blog ct-body standard">
<div id="overflow-container" class="overflow-container">
  <a class="skip-content" href="#main">Skip to content</a>
  <header id="site-header" class="site-header" role="banner">
    <div class='top-navigation top-navigation-important'>
        <div class='container'>
            <div id="menu-secondary" class="menu-container menu-secondary" role="navigation">
                <button id="toggle-secondary-navigation" class="toggle-secondary-navigation"><i class="fa fa-plus"></i></button>
                <div class="menu">
                    <ul id="menu-secondary-items" class="menu-secondary-items">
                        
                        
                            
                        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
                            <a href="https://sixi.fun/tag/i__JBem5D">人生苦短，我用Python</a>
                        </li>
                            
                        
                            
                        <li id="menu-item" class="menu-item menu-item-type-taxonomy menu-item-object-category menu-item">
                            <a href="https://sixi.fun/tag/Awb26QpLB">渗透从入门到放弃</a>
                        </li>
                            
                        
                    </ul>
                </div>
            </div>
            <ul class="social-media-icons">
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </div>
    </div>

    <div class="container">
        <div id="title-info" class="title-info">
            <div id='site-title' class='site-title'>
                <a href="https://sixi.fun">  一只小菜鸡 </a>
            </div>
        </div>
        <button id="toggle-navigation" class="toggle-navigation">
            <i class="fa fa-bars"></i>
        </button>
        <div id="menu-primary-tracks" class="menu-primary-tracks"></div>
        <div id="menu-primary" class="menu-container menu-primary" role="navigation">
            <p class="site-description">温故而知新</p>
            <div class="menu">
                <ul id="menu-primary-items" class="menu-primary-items">
                     
                        
                            <li id="menu-item" class='menu-item menu-item-type-post_type menu-item-object-page current-menu-item current_page_item'>
                                <a href="/">首页</a>
                            </li>
                        
                    
                        
                            <li id="menu-item" class='menu-item menu-item-type-post_type menu-item-object-page current-menu-item current_page_item'>
                                <a href="/archives">归档</a>
                            </li>
                        
                    
                        
                            <li id="menu-item" class='menu-item menu-item-type-post_type menu-item-object-page current-menu-item current_page_item'>
                                <a href="/tags">标签</a>
                            </li>
                        
                    
                        
                            <li id="menu-item" class='menu-item menu-item-type-post_type menu-item-object-page current-menu-item current_page_item'>
                                <a href="/post/about">关于</a>
                            </li>
                        
                    
                </ul>
            </div>
        </div>
    </div>


</header>


  <div id="main" class="main" role="main">
    <div id="loop-container" class="loop-container">
      <div class="post type-post status-publish format-standard has-post-thumbnail hentry category-design tag-design tag-standard-2 tag-tagalicious tag-travel entry full-without-featured odd excerpt-1">
        
          <div class='featured-image lazy lazy-bg-image' data-background="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/python2.jpeg">
          </div>
        

        <div class="entry-meta">
          <span class="date">· 2019-06-14 ·</span> <span> / </span>
          <span class="author">
            <a href="https://sixi.fun" title="" rel="author"> Powered by <a>LCCL</a></a>
          </span>
          
            <span class="category">
                    <span> / </span>
                    <a href="https://sixi.fun/tag/i__JBem5D">人生苦短，我用Python</a>
                </span>
          
        </div>
        <div class='entry-header'>
          <h1 class='entry-title'>我的第一个python爬虫</h1>
        </div>
        <div class="entry-container">
          <div class="entry-content">
            <article>
              <h4 id="初识python">初识python</h4>
<pre><code>  从大二开始接触python，那时候在实验室跟舍友做一个机器学习相关的项目，之后在期末的数据结构实训中也是运用python这门语言进行代码的编写，深刻的感受到了python的乐趣。此次爬虫是在这学期网络攻击与防御的课程中，学校跟e春秋合作推出了线上自学靶场平台，里面有许多网络攻击与防御相关的视频。于是产生了写一个爬虫将视频下载下来保存的想法。一方面保存学习资源，一方面练习编程技巧。
</code></pre>
<h4 id="艰难历程">艰难历程</h4>
<pre><code>  期初有想法是完全不会的，之前学习的语法也忘了，因为python是零零星星在学，没有一次系统的学习过。于是找到了一套完整的python全栈开发视频，将里面的爬虫模块的技术看了一半，便开始编写，由于只能在机房才能连上服务器，来回机房跑了几次，另外花了几节课才调试出来。其中还有许多不足，等技术成熟了再优化代码。
</code></pre>
<p><img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/2.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/3.png" alt=""></p>
<h4 id="代码">代码</h4>
<pre><code>代码思路和实现过程，在面向对象的类里写的很清楚，就不阐述了。运用的模块也蛮简单，就requests请求模块，随机数模块random（），用于随机选择用户，登录获取用户登录信息的cookie，存在session对象中。实现用户的分布式爬取，反反爬虫。 用etree模块处理响应的数据，并用xpath提取下一步所需的信息，保存到列表中以供下一步访问。os模块用于创建课程相应文件夹和每一小节的名字并存储到相应文件夹。
</code></pre>
<h5 id="面向对象">面向对象</h5>
<p>（图片，便于浏览）
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code1.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code2.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code3.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code4.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code5.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code6.png" alt=""></p>
<p>（手机版排版效果不好，请用电脑浏览以下代码）</p>
<pre><code class="language-python">import re
import requests
import random
from lxml import etree
import os
class Spider():
    def __init__(self):
        self.headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0&quot;}
        self.post_url = &quot;http://192.168.4.253/index.php/Login/login&quot;
        self.post_data = [{&quot;username&quot;: &quot;luochen&quot;, &quot;password&quot;: &quot;passwd&quot;}]
        self.Big_url = &quot;http://192.168.4.253/index.php/Study/studydetail?taskid={}&quot;

    def load(self):  # 登录获取第一页内容
        post_data = random.choice(self.post_data)
        session = requests.session()
        session.post(self.post_url, data=post_data, headers=self.headers)
        for i in range(1, 3):
            one_url=&quot;http://192.168.4.253/index.php/Study/listunderway?per_page={}&quot;
            response =session.get(one_url.format(i), headers=self.headers)
        return response.content.decode()

    def Big_url(self,first_data):  # 提取TaskID构造下一级url
        html = etree.HTML(first_data.content.decode())
        ret=html.xpath('//div[@class=&quot;taskimg&quot;]//a/@taskid')
        Big_url=[]
        for i in range(0, len(ret)):
            Big_url.append(&quot;http://192.168.4.253/index.php/Study/studydetail?taskid={}&quot;.format(ret[i]))
        return Big_url

    def Big_title(self,first_data):
        html = etree.HTML(first_data.content.decode())
        Bigtit_list=html.xpath('//div[@class=&quot;taskimg&quot;]//a/@title')
        return Bigtit_list


    def crate_big_file(self,Bigtit_list):       #创建相应文件夹
        for Bigtit in Bigtit_list:
            #print(Bigtit,Bighref)
            if os.path.exists(Bigtit)==False:#判断有无此文件夹
                os.mkdir(Bigtit)          #创建文件夹

    def load_little_url(self, bigurl):#进入二级url，得到课程的详细信息
        post_data = random.choice(self.post_data)
        session = requests.session()
        session.post(self.post_url, data=post_data, headers=self.headers)
        response = session.get(bigurl, headers=self.headers)
        return response.content.decode()

    # 获取三级url地址
    def Little_url(self,second_data):
        html = etree.HTML(second_data.content.decode())
        Little_url_list=html.xpath('//p[@class=&quot;itemTitle&quot; ]//a//@href')
        return Little_url_list

    def Little_title(self,second_data):
        html = etree.HTML(second_data.content.decode())
        Little_title_list=html.xpath('//p[@class=&quot;itemTitle&quot; ]//a/text()')
        return Little_title_list

    def load_third_url(self,little_url): #进入视频播放页面，发送请求获取数据
        post_data = random.choice(self.post_data)
        session = requests.session()
        session.post(self.post_url, data=post_data, headers=self.headers)
        response = session.get(little_url, headers=self.headers)
        return response.content.decode()

    def vedio_url(self,vedio_page_data):
        html = etree.HTML(vedio_page_data.content.decode())
        vedio_url=html.xpath('//vedio//source/@src')
        return vedio_url

    def save_vedio(self,vedio_url,bigtitle,little_title):
        post_data = random.choice(self.post_data)
        session = requests.session()
        session.post(self.post_url, data=post_data, headers=self.headers)
        response = session.get(vedio_url, headers=self.headers)
        little_title = re.sub(':', &quot; &quot;, little_title)  # 替换掉标题中的冒号
        path = bigtitle + &quot;\\&quot; + little_title + &quot;.mp4&quot;
        if os.path.exists(path) == False:
            with open(path,&quot;wb&quot;) as f:
                f.write(response.content)
                f.close()

    def seve_page(self,vedio_page_data,little_title,bigtitle):
        little_title = re.sub(':', &quot; &quot;, little_title)  # 替换掉标题中的冒号
        path = bigtitle + &quot;\\&quot; + little_title + &quot;.html&quot;
        with open(path,&quot;w&quot;,encoding=&quot;utf-8&quot;) as f:
            f.write(vedio_page_data)
            f.close()

    def run(self):
        # 登录发送请求获取响应
        first_data = self.load()
        # 爬取所有课程名字和url
        Bigurl_list=self.Big_url(first_data)
        Bigtit_list=self.Big_title(first_data)
        # 创建相应课程文件夹
        self.crate_big_file(Bigtit_list)
        #进入二级url
        for bigurl,bigtitle in zip(Bigurl_list,Bigtit_list):
            second_data=self.load_little_url(bigurl)
            # 获取每一小节名字和url
            Little_url_list=self.Little_url(second_data)
            Little_title_list=self.Little_title(second_data)
            print(Little_title_list,Little_url_list)
        #进入视频播放
            for little_url,little_title in zip(Little_url_list,Little_title_list):
                vedio_page_data=self.load_third_url(little_url)
                vedio_url=self.vedio_url(vedio_page_data)
                # 判断是视频还是文本教程
                if len(vedio_url)&gt;0:
                    try:
                    # 若是视频，提取视频地址，下载保存
                        self.save_vedio(vedio_url[0],bigtitle,little_title)
                    except Exception as e:
                        print(e)
                else:
                    try:
                    # 若是网页教程，保存为HTML格式文件
                        self.seve_page(vedio_page_data,bigtitle,little_title)
                    except Exception as e:
                        print(e)

if __name__ == '__main__':
    spider=Spider()
    spider.run()

</code></pre>
<p>以上代码是面向对象过程，但是在运行过程中有些问题导致报错，还没解决。但是思路是完全正确的，花了些时间把代码改成非面向对象版，代码完美运行：</p>
<h4 id="非面向对象版代码">非面向对象版代码</h4>
<p><img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code7.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code8.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code9.png" alt="">
<img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/code10.png" alt=""></p>
<pre><code class="language-python">import requests
import random
from lxml import etree
import os
import re
requests.adapters.DEFAULT_RETRIES = 5
headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0&quot;}
post_url = &quot;http://192.168.4.253/index.php/Login/login&quot;
post_data = [{&quot;username&quot;: &quot;luochen&quot;, &quot;password&quot;: &quot;passwd&quot;}]
Big_url = &quot;http://192.168.4.253/index.php/Study/studydetail?taskid={}&quot;
post_data = random.choice(post_data)
session = requests.session()
session.post(post_url, data=post_data, headers=headers)
for i in range(1, 3):
    one_url = &quot;http://192.168.4.253/index.php/Study/listunderway?per_page={}&quot;
    first_data = session.get(one_url.format(i), headers=headers)

    html = etree.HTML(first_data.content.decode())
    ret = html.xpath('//div[@class=&quot;taskimg&quot;]//a/@taskid')
    Big_url = []
    for i in range(0, len(ret)):
        Big_url.append(&quot;http://192.168.4.253/index.php/Study/studydetail?taskid={}&quot;.format(ret[i]))
    print(Big_url)

    Bigtit_list = html.xpath('//div[@class=&quot;taskimg&quot;]//a/@title')
    print(Bigtit_list)
    for Bigtit in Bigtit_list:
        # print(Bigtit,Bighref)
        if os.path.exists(Bigtit) == False:  # 判断有无此文件夹
            os.mkdir(Bigtit)

    for bigurl, bigtitle in zip(Big_url, Bigtit_list):
        second_data = session.get(bigurl, headers=headers)
        html = etree.HTML(second_data.content.decode())
        Little_title_list = html.xpath('//p[@class=&quot;itemTitle&quot; ]//a/text()')
        Little_url_list = html.xpath('//p[@class=&quot;itemTitle&quot; ]//a//@href')

        for little_url, little_title in zip(Little_url_list, Little_title_list):
            vedio_page_data = session.get(little_url, headers=headers)
            html = etree.HTML(vedio_page_data.content.decode())
            vedio_url = html.xpath('//video//source/@src')
            if len(vedio_url) &gt; 0:
                # ren = &quot;.*?(:)*?&quot;
                little_title= re.sub(':', &quot; &quot;, little_title)   #替换掉标题中的冒号
                print(bigtitle)
                path = bigtitle + &quot;\\&quot; + little_title + &quot;.mp4&quot;
                try:
                    vedio_data=session.get(vedio_url[0])
                    with open(path, 'wb') as output:
                        while True:
                            buffer = vedio_data.read(1024 * 256);
                            if not buffer:
                                break
                            # received += len(buffer)
                            output.write(buffer)
                        output.close()
                    print(little_title + &quot;.mp4下载成功&quot;)

                except Exception as e:
                    print(e)

        else:
            try:
                html_data = vedio_page_data.content
                fail_path = bigtitle + &quot;\\&quot; + little_title + &quot;.html&quot;
                with open(fail_path, &quot;w&quot;,encoding=&quot;utf-8&quot;) as f:
                    f.write(html_data)
                    f.close()
print(little_title + &quot;.html下载成功&quot;)
            except Exception as e:
                print(e)
</code></pre>
<pre><code>当然，虽然此次爬取到了所想要的资源，但是以上代码也有许多地方可以优化，如可以使用多线程，多进程技术进行爬取，在实际互联网上还要增加用户代理池，ip代理池等反反爬技术，以成功爬取所需的全部资源。美中不足的是本来想将网页一并爬取下来，但是如何处理每一张图片与连接的对应关系还没有思路，一个要学会了教程里的nosql数据库才能处理，所以这个问题先放一边。总共爬取了10个G的全部教学视频，收获还是不错的。
</code></pre>
<p><img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/2019-06-14_160712.png" alt=""></p>
<hr>
<h4 id="总结">总结：</h4>
<pre><code>  经历了这次独立的开发一个项目（ps:苍蝇再小也是肉）,对 面向对象和非面向对象有了一个非常深刻的认知，刷新了我对编程的理解，因为以前基本上都是照着代码敲，没有这么深刻的思考。也算是一个从零到一的突破吧！会的东西还很少，继续按照教程来选修自己感兴趣的模块。
</code></pre>
<hr>
<pre><code>		吐槽一句，撸代码真的会让人秃头！！那些天思考实现方法，改bug，调程序，搞得我头皮发麻，整个人都是懵的。
		
		
继续加油学习吧，这个年纪，迷茫的时候就只管学习就好，其他的交给命运。
</code></pre>
<p><img src="https://blog-1259440694.cos.ap-chengdu.myqcloud.com/2%20python/5.jpeg" alt=""></p>

            </article>
          </div>
          <div class='entry-meta-bottom'>
            <div class="entry-categories">
              <p>
                <span>Categories</span>
                
                  
                    
                  <a href="https://sixi.fun/tag/i__JBem5D" title="View all posts in 人生苦短，我用Python">人生苦短，我用Python</a>
                    
                    
                    
                  <a href="https://sixi.fun/tag/Awb26QpLB" title="View all posts in 渗透从入门到放弃">渗透从入门到放弃</a>
                    
                    
              </p>
            </div>
            <div class="entry-tags">
              <p><span>Tags</span>
              </p>
            </div>
          </div>
          <div class="author-meta">
            <div class="author">
              <img alt='' src="https://sixi.fun/images/avatar.png?v=1560515429400" class='avatar avatar-72 photo' height='72' width='72'>
              <span>WRITTEN BY: &nbsp;&nbsp;&nbsp;<a href='https://sixi.fun'></a> </span>
            </div>
            <div class="bio">
              <p></p>
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
                
              
            </div>
          </div>
        </div>
          
            <nav class="navigation pagination" role="navigation">
              <h2 class="screen-reader-text">Posts navigation</h2>
              <div class="nav-links">
                <a class="next page-numbers" href="https://sixi.fun/post/yong-metasploit-fan-dan-shell-shen-tou-mu-biao-shou-ji-huo-windows-she-bei">下一篇->用Metasploit反弹shell渗透目标手机或Windows设备</a>
              </div>
            </nav>
          
      </div>
      <section id="comments" class="comments">
        
      </section>
    </div>
  </div>
  <footer id="site-footer" class="site-footer" role="contentinfo">
    <h1>
        <a href="https://sixi.fun"> 一只小菜鸡 </a>
    </h1>
    <p class="site-description">温故而知新</p>
    <div id="menu-footer" class="menu-container menu-footer" role="navigation">
        <div class="menu">
            <ul id="menu-footer-items" class="menu-footer-items">
            </ul>
        </div>
    </div>
    <ul class="social-media-icons">
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
            
        
    </ul>
    <div class="design-credit">
        <p>Powered by <a>LCCL</a></p>
    </div>
</footer>
<script>
    hljs.initHighlightingOnLoad()
</script>
<script src="https://sixi.fun/media/scripts/lib/jquery.min.js"></script>
<script src="https://sixi.fun/media/scripts/lib/jquerymigrate.js"></script>
<script src="https://sixi.fun/media/scripts/lib/production.min.js"></script>

</div>
</body>
</html>

